{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venu019/final-year-project/blob/main/finalyear%20project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70yitELAbGNa",
      "metadata": {
        "id": "70yitELAbGNa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "06b94db4",
      "metadata": {
        "id": "06b94db4"
      },
      "source": [
        "#                                     TASK -- 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VnFxcYexSLrT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnFxcYexSLrT",
        "outputId": "aa52e053-c183-4265-bcb9-09c8063d0af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba4d3c1",
      "metadata": {
        "id": "fba4d3c1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf59f356",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bf59f356",
        "outputId": "e2362c3f-803a-4a09-b0bf-a119308e6a5e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15383,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15355,\n        \"samples\": [\n          \"this should not be called or even considered womensmarch real women do not lend themselves or rely on this new feminist bullshit its superflous judgejudy said it best when she owned katie couric these girls have no love let alone respect for themselves in return they recieve none slagfest\",\n          \"weev is a kike and ricky is a soy nigger\",\n          \"iranians and arabs lived in sweden when you were a kid i did not know thought i thought sweden was fairly homogenous until recently\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"hatespeech\",\n          \"offensive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2dc7c48b-68ce-453f-a78b-3be9c5b32f2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we cannot continue calling ourselves feminists...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nawt yall niggers ignoring me</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
              "      <td>hatespeech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and this is why i end up with nigger trainee d...</td>\n",
              "      <td>hatespeech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nogs jews and dykes how enriching</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dc7c48b-68ce-453f-a78b-3be9c5b32f2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dc7c48b-68ce-453f-a78b-3be9c5b32f2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dc7c48b-68ce-453f-a78b-3be9c5b32f2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a7fba57a-735c-4425-8521-25c1df774c77\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7fba57a-735c-4425-8521-25c1df774c77')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a7fba57a-735c-4425-8521-25c1df774c77 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text        type\n",
              "0  we cannot continue calling ourselves feminists...      normal\n",
              "1                      nawt yall niggers ignoring me      normal\n",
              "2  <user> i am bit confused coz chinese ppl can n...  hatespeech\n",
              "3  and this is why i end up with nigger trainee d...  hatespeech\n",
              "4                  nogs jews and dykes how enriching   offensive"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_train.tsv\", sep='\\t',header=None)\n",
        "df.columns = ['text', 'type']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472fe5e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "472fe5e0",
        "outputId": "b3d4e870-c274-4f7b-ade2-80510ece24f2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 1922,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1922,\n        \"samples\": [\n          \"over the last week i was thinking that altretard pedo nazi faggot would become like the ultimate insult and then pewdiepie said nigger and the world came to an end no no apparently even the feelings of the altleft are retarded and unimaginataive\",\n          \"whoever made this thread has the big gay\",\n          \"<user> a bunch of poor refugees a thousand miles away no hussein more like <number> million voting illegal aliens already within our own borders that is the existential threat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"hatespeech\",\n          \"offensive\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_val"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-192ad8cb-2778-42dc-800b-30ea8ed3ffc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this bitch in whataburger eating a burger with...</td>\n",
              "      <td>hatespeech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tired i can not support abortion from a moral ...</td>\n",
              "      <td>hatespeech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all of my exes were cute but they were hoes i ...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;user&gt; &lt;user&gt; they visited helped provided foo...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it funny how people offended by the word nigge...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-192ad8cb-2778-42dc-800b-30ea8ed3ffc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-192ad8cb-2778-42dc-800b-30ea8ed3ffc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-192ad8cb-2778-42dc-800b-30ea8ed3ffc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad8360f9-9e40-4ee4-bb8f-7655ece88cde\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad8360f9-9e40-4ee4-bb8f-7655ece88cde')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad8360f9-9e40-4ee4-bb8f-7655ece88cde button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text        type\n",
              "0  this bitch in whataburger eating a burger with...  hatespeech\n",
              "1  tired i can not support abortion from a moral ...  hatespeech\n",
              "2  all of my exes were cute but they were hoes i ...   offensive\n",
              "3  <user> <user> they visited helped provided foo...      normal\n",
              "4  it funny how people offended by the word nigge...      normal"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_valid.tsv\", sep='\\t',header=None)\n",
        "df_val.columns = ['text', 'type']\n",
        "df_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6116d52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d6116d52",
        "outputId": "bcd4879e-8f61-4554-8f73-1fb538b89bd0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 1924,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1923,\n        \"samples\": [\n          \"am not trying to be racist some of them mmg rude especially arabs mabuk tu takyah cerita la dah mabuk blh pulak drive \\ud83e\\udd26 \\u200d \\u2642 \\ufe0f\",\n          \"a very important point this is why they want to demonize white ancestors so that we become disconnected from and reject the wonderful legacy of our own past and the incredible accomplishments of those who came before us\",\n          \"<user> a redneck woman\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"normal\",\n          \"hatespeech\",\n          \"offensive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9302f42d-7ea0-4e69-a95c-4a7ba3104e36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i dont think im getting my baby them white 9 h...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>laura loomer raped me while screaming at me in...</td>\n",
              "      <td>hatespeech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;user&gt; what did the old lady do was she a nazi...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>as much as i appreciate a format of open discu...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sex be so good a bitch be slow stroking and cr...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9302f42d-7ea0-4e69-a95c-4a7ba3104e36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9302f42d-7ea0-4e69-a95c-4a7ba3104e36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9302f42d-7ea0-4e69-a95c-4a7ba3104e36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e094d85-9f2d-4113-8077-a97a28d84754\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e094d85-9f2d-4113-8077-a97a28d84754')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e094d85-9f2d-4113-8077-a97a28d84754 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text        type\n",
              "0  i dont think im getting my baby them white 9 h...      normal\n",
              "1  laura loomer raped me while screaming at me in...  hatespeech\n",
              "2  <user> what did the old lady do was she a nazi...      normal\n",
              "3  as much as i appreciate a format of open discu...      normal\n",
              "4  sex be so good a bitch be slow stroking and cr...   offensive"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_test.tsv\", sep='\\t',header=None)\n",
        "df_test.columns = ['text', 'type']\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hlHp8qGOvSBC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlHp8qGOvSBC",
        "outputId": "c694a2c8-d1c2-4a68-c6fe-28f67c8f7f4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7945e523",
      "metadata": {
        "id": "7945e523"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem  import  WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words=stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "snow_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "def preprocessor(text):\n",
        "    text=text.split()\n",
        "    text=[snow_stemmer.stem(w) for w in text]\n",
        "    text=[lemmatizer.lemmatize(w,pos=\"a\") for w in text]\n",
        "    text=[w  for w in text if not w in stop_words]\n",
        "    text=' '.join(text)\n",
        "    text = re.sub(r'[^A-Za-z1-9 ]', ' ', text)\n",
        "    return text\n",
        "df['text']=df['text'].apply(preprocessor)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53844454",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "53844454"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim import models\n",
        "\n",
        "word2vec_path = '/content/drive/MyDrive/Final Project/GoogleNews-vectors-negative300.bin'\n",
        "word2vec_model = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e76793",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b8e76793"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def get_input_features(dataframe):\n",
        "    input_features = []\n",
        "    for text in dataframe:\n",
        "        # Initialize an empty array for the text\n",
        "        feature_vector = np.zeros((word2vec_model.vector_size,))\n",
        "        num_words = 0\n",
        "        for word in text:\n",
        "            if word in word2vec_model:\n",
        "                feature_vector = np.add(feature_vector, word2vec_model[word])\n",
        "                num_words += 1\n",
        "        # Average the word vectors to get the feature vector for the text\n",
        "        if num_words > 0:\n",
        "            feature_vector = np.divide(feature_vector, num_words)\n",
        "        input_features.append(feature_vector)\n",
        "\n",
        "    # Convert input features and target labels to PyTorch tensors\n",
        "    input_features = torch.tensor(input_features, dtype=torch.float32)\n",
        "    print(input_features)\n",
        "    return input_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xun5RM5goyZO",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xun5RM5goyZO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f99043",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "64f99043",
        "outputId": "34f6bcdb-50b9-4428-8517-0973976adad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1755,  0.1131, -0.0035,  ..., -0.0304, -0.1185,  0.1520],\n",
            "        [-0.1903,  0.0728, -0.0098,  ..., -0.0539, -0.1586,  0.1391],\n",
            "        [-0.1972,  0.0909, -0.0102,  ..., -0.0204, -0.0993,  0.1629],\n",
            "        ...,\n",
            "        [-0.1592,  0.1066, -0.0449,  ..., -0.0195, -0.1386,  0.1377],\n",
            "        [-0.1701,  0.1159, -0.0096,  ..., -0.0314, -0.1347,  0.1612],\n",
            "        [-0.1863,  0.1108, -0.0183,  ..., -0.0206, -0.1020,  0.1308]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-f412a319457f>:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  input_features = torch.tensor(input_features, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "input_features=get_input_features(df['text'])\n",
        "# target_labels=['normal','hatespeech','offensive']\n",
        "target_labels=df['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "target_labels = torch.tensor(target_labels, dtype=torch.long)\n",
        "\n",
        "# Number of target classes in the dataset\n",
        "num_classes = 3  # Specify the number of target classes\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, y_train =input_features, target_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "402774ff",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "402774ff"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec28e35",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6ec28e35",
        "outputId": "6af7778b-31ca-425c-a958-4d06b3aa8e4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 481/481 [00:01<00:00, 345.11it/s]\n",
            "100%|| 481/481 [00:01<00:00, 251.34it/s]\n",
            "100%|| 481/481 [00:01<00:00, 313.00it/s]\n",
            "100%|| 481/481 [00:01<00:00, 291.39it/s]\n",
            "100%|| 481/481 [00:02<00:00, 227.44it/s]\n",
            "100%|| 481/481 [00:02<00:00, 239.71it/s]\n",
            "100%|| 481/481 [00:01<00:00, 310.09it/s]\n",
            "100%|| 481/481 [00:01<00:00, 310.52it/s]\n",
            "100%|| 481/481 [00:01<00:00, 325.22it/s]\n",
            "100%|| 481/481 [00:01<00:00, 285.51it/s]\n",
            "100%|| 481/481 [00:01<00:00, 313.42it/s]\n",
            "100%|| 481/481 [00:01<00:00, 310.47it/s]\n",
            "100%|| 481/481 [00:02<00:00, 233.73it/s]\n",
            "100%|| 481/481 [00:02<00:00, 234.56it/s]\n",
            "100%|| 481/481 [00:01<00:00, 332.67it/s]\n",
            "100%|| 481/481 [00:01<00:00, 332.43it/s]\n",
            "100%|| 481/481 [00:01<00:00, 320.38it/s]\n",
            "100%|| 481/481 [00:01<00:00, 319.78it/s]\n",
            "100%|| 481/481 [00:01<00:00, 315.69it/s]\n",
            "100%|| 481/481 [00:01<00:00, 329.73it/s]\n",
            "100%|| 481/481 [00:01<00:00, 268.78it/s]\n",
            "100%|| 481/481 [00:02<00:00, 222.67it/s]\n",
            "100%|| 481/481 [00:01<00:00, 276.65it/s]\n",
            "100%|| 481/481 [00:01<00:00, 310.99it/s]\n",
            "100%|| 481/481 [00:01<00:00, 320.01it/s]\n",
            "100%|| 481/481 [00:01<00:00, 312.89it/s]\n",
            "100%|| 481/481 [00:01<00:00, 317.39it/s]\n",
            "100%|| 481/481 [00:01<00:00, 327.72it/s]\n",
            "100%|| 481/481 [00:01<00:00, 283.05it/s]\n",
            "100%|| 481/481 [00:02<00:00, 235.37it/s]\n",
            "100%|| 481/481 [00:01<00:00, 244.07it/s]\n",
            "100%|| 481/481 [00:01<00:00, 309.84it/s]\n",
            "100%|| 481/481 [00:01<00:00, 319.28it/s]\n",
            "100%|| 481/481 [00:01<00:00, 324.35it/s]\n",
            "100%|| 481/481 [00:01<00:00, 310.67it/s]\n",
            "100%|| 481/481 [00:01<00:00, 301.80it/s]\n",
            "100%|| 481/481 [00:01<00:00, 312.76it/s]\n",
            "100%|| 481/481 [00:02<00:00, 222.84it/s]\n",
            "100%|| 481/481 [00:02<00:00, 214.39it/s]\n",
            "100%|| 481/481 [00:01<00:00, 304.63it/s]\n",
            "100%|| 481/481 [00:01<00:00, 316.86it/s]\n",
            "100%|| 481/481 [00:01<00:00, 312.37it/s]\n",
            "100%|| 481/481 [00:01<00:00, 314.05it/s]\n",
            "100%|| 481/481 [00:01<00:00, 318.92it/s]\n",
            "100%|| 481/481 [00:01<00:00, 301.61it/s]\n",
            "100%|| 481/481 [00:02<00:00, 231.60it/s]\n",
            "100%|| 481/481 [00:02<00:00, 218.39it/s]\n",
            "100%|| 481/481 [00:01<00:00, 308.15it/s]\n",
            "100%|| 481/481 [00:01<00:00, 307.86it/s]\n",
            "100%|| 481/481 [00:01<00:00, 324.54it/s]\n",
            "100%|| 481/481 [00:01<00:00, 321.81it/s]\n",
            "100%|| 481/481 [00:01<00:00, 312.12it/s]\n",
            "100%|| 481/481 [00:01<00:00, 296.68it/s]\n",
            "100%|| 481/481 [00:01<00:00, 247.34it/s]\n",
            "100%|| 481/481 [00:02<00:00, 223.95it/s]\n",
            "100%|| 481/481 [00:01<00:00, 293.27it/s]\n",
            "100%|| 481/481 [00:01<00:00, 319.35it/s]\n",
            "100%|| 481/481 [00:01<00:00, 299.39it/s]\n",
            "100%|| 481/481 [00:01<00:00, 320.58it/s]\n",
            "100%|| 481/481 [00:01<00:00, 316.91it/s]\n",
            "100%|| 481/481 [00:01<00:00, 322.30it/s]\n",
            "100%|| 481/481 [00:01<00:00, 303.09it/s]\n",
            "100%|| 481/481 [00:02<00:00, 230.17it/s]\n",
            "100%|| 481/481 [00:01<00:00, 246.29it/s]\n",
            "100%|| 481/481 [00:01<00:00, 313.00it/s]\n",
            "100%|| 481/481 [00:01<00:00, 322.47it/s]\n",
            "100%|| 481/481 [00:01<00:00, 323.21it/s]\n",
            "100%|| 481/481 [00:01<00:00, 315.37it/s]\n",
            "100%|| 481/481 [00:04<00:00, 99.45it/s]\n",
            "100%|| 481/481 [00:03<00:00, 133.75it/s]\n",
            "100%|| 481/481 [00:02<00:00, 237.55it/s]\n",
            "100%|| 481/481 [00:01<00:00, 317.91it/s]\n",
            "100%|| 481/481 [00:01<00:00, 328.57it/s]\n",
            "100%|| 481/481 [00:01<00:00, 322.04it/s]\n",
            "100%|| 481/481 [00:01<00:00, 309.80it/s]\n",
            "100%|| 481/481 [00:01<00:00, 305.12it/s]\n",
            "100%|| 481/481 [00:01<00:00, 305.16it/s]\n",
            "100%|| 481/481 [00:02<00:00, 223.97it/s]\n",
            "100%|| 481/481 [00:02<00:00, 226.28it/s]\n",
            "100%|| 481/481 [00:01<00:00, 323.32it/s]\n",
            "100%|| 481/481 [00:01<00:00, 324.23it/s]\n",
            "100%|| 481/481 [00:01<00:00, 309.02it/s]\n",
            "100%|| 481/481 [00:01<00:00, 311.99it/s]\n",
            "100%|| 481/481 [00:01<00:00, 310.24it/s]\n",
            "100%|| 481/481 [00:01<00:00, 293.38it/s]\n",
            "100%|| 481/481 [00:01<00:00, 240.74it/s]\n",
            "100%|| 481/481 [00:02<00:00, 213.67it/s]\n",
            "100%|| 481/481 [00:01<00:00, 287.09it/s]\n",
            "100%|| 481/481 [00:01<00:00, 294.44it/s]\n",
            "100%|| 481/481 [00:01<00:00, 275.67it/s]\n",
            "100%|| 481/481 [00:01<00:00, 280.53it/s]\n",
            "100%|| 481/481 [00:01<00:00, 283.66it/s]\n",
            "100%|| 481/481 [00:01<00:00, 285.06it/s]\n",
            "100%|| 481/481 [00:02<00:00, 208.39it/s]\n",
            "100%|| 481/481 [00:02<00:00, 227.66it/s]\n",
            "100%|| 481/481 [00:01<00:00, 265.67it/s]\n",
            "100%|| 481/481 [00:01<00:00, 284.22it/s]\n",
            "100%|| 481/481 [00:01<00:00, 274.76it/s]\n",
            "100%|| 481/481 [00:01<00:00, 285.16it/s]\n",
            "100%|| 481/481 [00:01<00:00, 287.65it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = word2vec_model.vector_size\n",
        "hidden_size1 = 128\n",
        "hidden_size2 = 64\n",
        "output_size = num_classes\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size1, hidden_size2, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "#         print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10c643b",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d10c643b",
        "outputId": "d9fcb789-5935-48d1-c3b5-2d53b3eba4fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2130,  0.1123, -0.0293,  ..., -0.0450, -0.1160,  0.1380],\n",
            "        [-0.1900,  0.1296, -0.0274,  ..., -0.0435, -0.1059,  0.1520],\n",
            "        [-0.1914,  0.1235, -0.0154,  ..., -0.0361, -0.1106,  0.1733],\n",
            "        ...,\n",
            "        [-0.1918,  0.1106,  0.0011,  ..., -0.0245, -0.0942,  0.1484],\n",
            "        [-0.1813,  0.1095, -0.0176,  ..., -0.0265, -0.1170,  0.1440],\n",
            "        [-0.1814,  0.1310, -0.0147,  ..., -0.0350, -0.1116,  0.1489]])\n",
            "Test Set Accuracy: 45.01%\n"
          ]
        }
      ],
      "source": [
        "X_val, y_val =df_val['text'],df_val['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "X_val=get_input_features(X_val)\n",
        "# Evaluating the model on the validation set\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = torch.sum(predicted == y_val).item() / y_val.size(0)\n",
        "print(\"Test Set Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'best_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "151b1a06",
      "metadata": {
        "id": "151b1a06"
      },
      "source": [
        "# Accuracy using test data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1779ead4",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1779ead4",
        "outputId": "7372d9d3-ea20-4c31-eb93-b84f64b0d221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1789,  0.1060, -0.0296,  ..., -0.0277, -0.1229,  0.1210],\n",
            "        [-0.1815,  0.1169, -0.0059,  ..., -0.0231, -0.1220,  0.1406],\n",
            "        [-0.2034,  0.1393, -0.0222,  ..., -0.0430, -0.1051,  0.1480],\n",
            "        ...,\n",
            "        [-0.1856,  0.1189,  0.0099,  ..., -0.0400, -0.1082,  0.1494],\n",
            "        [-0.1927,  0.1216, -0.0069,  ..., -0.0455, -0.1053,  0.1543],\n",
            "        [-0.1529,  0.1079, -0.0186,  ..., -0.0126, -0.1185,  0.1297]])\n",
            "Test Set Accuracy: 43.81%\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test =df_test['text'],df_test['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "X_test=get_input_features(X_test)\n",
        "# Evaluating the model on the validation set\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = torch.sum(predicted == y_test).item() / y_test.size(0)\n",
        "\n",
        "print(\"Test Set Accuracy: {:.2f}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mh26vUXBjsgG",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Mh26vUXBjsgG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dXnLtec9Yspo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXnLtec9Yspo",
        "outputId": "41fb76d7-36dd-423a-fad0-bd264d6b9279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Set Metrics:\n",
            "Accuracy: 44.95%\n",
            "Precision: 0.44\n",
            "Recall: 0.41\n",
            "F1 Score: 0.40\n",
            "\n",
            "Test Set Metrics:\n",
            "Accuracy: 45.95%\n",
            "Precision: 0.45\n",
            "Recall: 0.42\n",
            "F1 Score: 0.41\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_val)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = accuracy_score(y_val, predicted)\n",
        "    precision = precision_score(y_val, predicted, average='macro')\n",
        "    recall = recall_score(y_val, predicted, average='macro')\n",
        "    f1 = f1_score(y_val, predicted, average='macro')\n",
        "\n",
        "print(\"Validation Set Metrics:\")\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1 Score: {:.2f}\".format(f1))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = accuracy_score(y_test, predicted)\n",
        "    precision = precision_score(y_test, predicted, average='macro')\n",
        "    recall = recall_score(y_test, predicted, average='macro')\n",
        "    f1 = f1_score(y_test, predicted, average='macro')\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1 Score: {:.2f}\".format(f1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e90bb4",
      "metadata": {
        "id": "e1e90bb4"
      },
      "source": [
        "#                                              TASK -- 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8cd290",
      "metadata": {
        "id": "4d8cd290"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qAdjEZcpCvkJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAdjEZcpCvkJ",
        "outputId": "441bc671-2216-474d-c5ed-9b34f259fd6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4b0781",
      "metadata": {
        "id": "8f4b0781"
      },
      "outputs": [],
      "source": [
        "# Sample raw text data\n",
        "df_train1 = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_train.tsv\", sep='\\t',header=None)\n",
        "df_train1.columns = ['text', 'type']\n",
        "raw_text_data = df_train1['text']  # Your raw text data goes here\n",
        "target_labels = df_train1['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)   # Your target labels go here\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Remove unnecessary symbols\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return words\n",
        "\n",
        "# Preprocess the raw text data\n",
        "processed_data = [preprocess_text(text) for text in raw_text_data]\n",
        "\n",
        "# Step 2: Create Vocabulary\n",
        "vocab = set(word for sentence in processed_data for word in sentence)\n",
        "\n",
        "# Step 3: Define Maximum Sequence Length\n",
        "max_seq_length = 50  # You can adjust this based on your dataset and task requirements\n",
        "\n",
        "# Step 4: Tokenize and Pad/Truncate Sentences\n",
        "word_to_idx = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
        "word_to_idx['<pad>'] = 0\n",
        "\n",
        "def encode_sentence(sentence):\n",
        "    encoded_sentence = [word_to_idx.get(word, 0) for word in sentence]\n",
        "    # Pad or truncate the sentence to the maximum sequence length\n",
        "    encoded_sentence = encoded_sentence[:max_seq_length] + [0] * (max_seq_length - len(encoded_sentence))\n",
        "    return encoded_sentence\n",
        "\n",
        "encoded_data = [encode_sentence(sentence) for sentence in processed_data]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d6c760",
      "metadata": {
        "id": "c5d6c760"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 5: load train, validation, and test sets\n",
        "df_val1 = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_valid.tsv\", sep='\\t',header=None)\n",
        "df_val1.columns = ['text', 'type']\n",
        "df_test1 = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_test.tsv\", sep='\\t',header=None)\n",
        "df_test1.columns = ['text', 'type']\n",
        "df_val1['text']=[preprocess_text(text) for text in df_val1['text']]\n",
        "df_test1['text']=[preprocess_text(text) for text in df_test1['text']]\n",
        "X_train, y_train = encoded_data, target_labels\n",
        "X_val,y_val = [encode_sentence(sentence) for sentence in df_val1['text']],df_val1['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "X_test, y_test = [encode_sentence(sentence) for sentence in df_test1['text']],df_test1['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "\n",
        "# Step 6: Define Dataloaders\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.tensor(data, dtype=torch.long)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataset = CustomDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66f5500",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "d66f5500",
        "outputId": "ca94897a-64c4-4285-9408-341b9627187e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Validation Loss: 1.0876\n",
            "Epoch [2/50], Validation Loss: 1.0864\n",
            "Epoch [3/50], Validation Loss: 1.0864\n",
            "Epoch [4/50], Validation Loss: 1.0867\n",
            "Epoch [5/50], Validation Loss: 0.9925\n",
            "Epoch [6/50], Validation Loss: 0.9434\n",
            "Epoch [7/50], Validation Loss: 0.9359\n",
            "Epoch [8/50], Validation Loss: 0.9530\n",
            "Epoch [9/50], Validation Loss: 1.0635\n",
            "Epoch [10/50], Validation Loss: 1.1260\n",
            "Epoch [11/50], Validation Loss: 1.1491\n",
            "Epoch [12/50], Validation Loss: 1.2632\n",
            "Early stopping. Loading the best model weights.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 7: Define Model Class\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers=1, dropout_prob=0.2):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)  #embedding layer\n",
        "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)   #rnn layer\n",
        "        self.dropout = nn.Dropout(dropout_prob) # Setting dropout for reducing overfitting\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  #classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.rnn(x)\n",
        "        output = output[:, -1, :]  # Use the last hidden state\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Apply softmax activation for predictions\n",
        "        x = F.softmax(self.forward(x), dim=1)\n",
        "        return x\n",
        "\n",
        "# Step 8: Train the Model with Early Stopping\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Number of target classes in the dataset\n",
        "num_classes = 3  # Specify the number of target classes\n",
        "\n",
        "model = RNNClassifier(vocab_size=len(vocab) + 1, embed_size=100, hidden_size=128, output_size=num_classes, num_layers=2, dropout_prob=0.2)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(100):  # You can adjust the number of epochs\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f'Epoch [{epoch+1}/50], Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping. Loading the best model weights.\")\n",
        "            break\n",
        "\n",
        "# Step 9: Load Best Model Weights\n",
        "model.load_state_dict(torch.load('best_rnn_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd84163",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4dd84163",
        "outputId": "9e693960-5e84-47b6-b6ba-a4cf818afb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.8925, Test Accuracy: 59.77%\n"
          ]
        }
      ],
      "source": [
        "# Step 10: Evaluate Model on Test Set\n",
        "model.eval()\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "test_loss = 0\n",
        "correct_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        test_loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct_predictions / len(y_test)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FYWw2pwrcxyE",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FYWw2pwrcxyE",
        "outputId": "8333d6a0-7c0a-4f04-a703-f9ad6d48c219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9359, Validation Accuracy: 57.18%\n",
            "Test Loss: 0.8925, Test Accuracy: 59.77%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the validation set\n",
        "model.eval()\n",
        "val_loss = 0\n",
        "correct_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        val_loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "val_loss /= len(val_loader)\n",
        "val_accuracy = correct_predictions / len(y_val)\n",
        "\n",
        "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss = 0\n",
        "correct_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        test_loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct_predictions / len(y_test)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rq4L2lXlgOqT",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rq4L2lXlgOqT",
        "outputId": "57f5f527-3758-438f-9665-b94c9ab47b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Set Metrics:\n",
            "Accuracy: 57.18%\n",
            "Precision: 0.56\n",
            "Recall: 0.56\n",
            "F1 Score: 0.56\n",
            "\n",
            "Test Set Metrics:\n",
            "Accuracy: 59.77%\n",
            "Precision: 0.59\n",
            "Recall: 0.58\n",
            "F1 Score: 0.59\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the validation set\n",
        "model.eval()\n",
        "val_loss = 0\n",
        "correct_predictions = 0\n",
        "val_predicted = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        val_loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        val_predicted.extend(predicted.tolist())\n",
        "\n",
        "val_loss /= len(val_loader)\n",
        "val_accuracy = correct_predictions / len(y_val)\n",
        "\n",
        "val_precision = precision_score(y_val, val_predicted, average='macro')\n",
        "val_recall = recall_score(y_val, val_predicted, average='macro')\n",
        "val_f1 = f1_score(y_val, val_predicted, average='macro')\n",
        "print(\"Validation Set Metrics:\")\n",
        "print(f\"Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {val_precision:.2f}\")\n",
        "print(f\"Recall: {val_recall:.2f}\")\n",
        "print(f\"F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss = 0\n",
        "correct_predictions = 0\n",
        "test_predicted = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        test_loss += criterion(outputs, labels).item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        test_predicted.extend(predicted.tolist())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct_predictions / len(y_test)\n",
        "\n",
        "test_precision = precision_score(y_test, test_predicted, average='macro')\n",
        "test_recall = recall_score(y_test, test_predicted, average='macro')\n",
        "test_f1 = f1_score(y_test, test_predicted, average='macro')\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {test_precision:.2f}\")\n",
        "print(f\"Recall: {test_recall:.2f}\")\n",
        "print(f\"F1 Score: {test_f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8eb114",
      "metadata": {
        "id": "ba8eb114"
      },
      "source": [
        "# TASK-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13cd1b34",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "13cd1b34",
        "outputId": "4f24a8f1-fbdf-484f-fda8-e2e089638e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Transformers installation\n",
        "! pip install transformers\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c643841e",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c643841e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C_se4-e50AnL",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C_se4-e50AnL",
        "outputId": "c0b737b7-e4bf-4ee1-fab6-80b4b662b60f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c048c6",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d2c048c6"
      },
      "outputs": [],
      "source": [
        "num_classes=3\n",
        "# Sample raw text data\n",
        "df_train1 = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_train.tsv\", sep='\\t',header=None)\n",
        "df_train1.columns = ['text', 'type']\n",
        "raw_text_data = df_train1['text']  # Your raw text data goes here\n",
        "target_labels = df_train1['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)   # Your target labels go here\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Remove unnecessary symbols\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Preprocess the raw text data\n",
        "processed_data = [preprocess_text(text) for text in raw_text_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vtk4-gf8M6FY",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vtk4-gf8M6FY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6518c015",
      "metadata": {
        "id": "6518c015"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load Model & Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TQd6kiteUhIE",
      "metadata": {
        "id": "TQd6kiteUhIE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba01de4",
      "metadata": {
        "id": "4ba01de4"
      },
      "outputs": [],
      "source": [
        "# Step 3: Dataloader Class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'text': self.texts[idx], 'label': self.labels[idx]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa58e7a0",
      "metadata": {
        "id": "fa58e7a0"
      },
      "outputs": [],
      "source": [
        "# Step 4: Create Model Class\n",
        "class CustomBERTClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes, dropout_prob=0.2):\n",
        "        super(CustomBERTClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffaabb11",
      "metadata": {
        "id": "ffaabb11"
      },
      "outputs": [],
      "source": [
        "# Step 5: Train Loop, Optimizers, Schedulers, Loss Function\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Step 5: load train, validation, and test sets\n",
        "df_val1 = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_valid.tsv\", sep='\\t',header=None)\n",
        "df_val1.columns = ['text', 'type']\n",
        "df_test1 = pd.read_csv(\"/content/drive/MyDrive/Final Project/NLP_ass_test.tsv\", sep='\\t',header=None)\n",
        "df_test1.columns = ['text', 'type']\n",
        "df_val1['text']=[preprocess_text(text) for text in df_val1['text']]\n",
        "df_test1['text']=[preprocess_text(text) for text in df_test1['text']]\n",
        "X_train, y_train = processed_data, target_labels\n",
        "X_val,y_val =df_val1['text'],df_val1['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "X_test, y_test = df_test1['text'],df_test1['type'].map( {'normal': 0, 'hatespeech': 1, 'offensive': 2} ).astype(int)\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "val_dataset = CustomDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=512)\n",
        "\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G1TaH9b3uujc",
      "metadata": {
        "id": "G1TaH9b3uujc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 8\n",
        "\n",
        "# Reduce batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Limit GPU memory usage\n",
        "torch.cuda.set_per_process_memory_fraction(0.7)  # Limit to 50% of GPU memory\n",
        "\n",
        "# Training loop with early stopping\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(50):  # You can adjust the number of epochs\n",
        "    model.train()\n",
        "    # Inside the training loop\n",
        "    for batch in train_loader:\n",
        "        input_texts = batch['text']\n",
        "        labels = torch.tensor(batch['label']).clone().detach().to(torch.long)  # Convert labels to torch.long data type\n",
        "        inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_texts = batch['text']\n",
        "            labels = torch.tensor(batch['label']).clone().detach().to(torch.long)\n",
        "            inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            val_loss += criterion(logits, labels).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f'Epoch [{epoch+1}/50], Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), 'best_bert_model.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping. Loading the best model weights.\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rhHbgNJNzAmR",
      "metadata": {
        "id": "rhHbgNJNzAmR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aadc4605",
      "metadata": {
        "id": "aadc4605"
      },
      "outputs": [],
      "source": [
        "# Step 7: Train the Model with Early Stopping\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(20):  # You can adjust the number of epochs\n",
        "    model.train()\n",
        "    # Inside the training loop\n",
        "    for batch in train_loader:\n",
        "        input_texts = batch['text']\n",
        "        labels = batch['label'].long()  # Convert labels to torch.long data type\n",
        "        inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_texts = batch['text']\n",
        "            labels = batch['label']\n",
        "            inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            val_loss += criterion(logits, labels).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f'Epoch [{epoch+1}/50], Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), 'best_bert_model.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping. Loading the best model weights.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2760fd49",
      "metadata": {
        "id": "2760fd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc340718-d88d-45f6-c04a-5b29726f87c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "\nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ce0597e7a3c5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize tokenizer and retriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/rag-token-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/rag-token-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Initialize sequence generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/rag/retrieval_rag.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"faiss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mRagConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mrag_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: \nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
        "\n",
        "# Initialize tokenizer and retriever\n",
        "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
        "retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")\n",
        "\n",
        "# Initialize sequence generator\n",
        "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")\n",
        "\n",
        "# Define a function to perform retrieval-augmented generation\n",
        "def generate_with_retrieval(prompt):\n",
        "    # Retrieve relevant passages\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        retriever_outputs = retriever(**inputs, return_tensors=\"pt\")\n",
        "    passage_input_ids = retriever_outputs['input_ids']\n",
        "    passage_attention_mask = retriever_outputs['attention_mask']\n",
        "\n",
        "    # Generate output sequence\n",
        "    generated = model.generate(input_ids=passage_input_ids,\n",
        "                               attention_mask=passage_attention_mask,\n",
        "                               max_length=100,\n",
        "                               num_return_sequences=1)\n",
        "\n",
        "    # Decode and return generated text\n",
        "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "# Read data from Excel file into DataFrame\n",
        "data = pd.read_excel(\"C:\\\\Users\\\\S.Revanth\\\\Downloads\\\\Vibration peridic table.xlsx\")\n",
        "\n",
        "# Process each row of the DataFrame\n",
        "for index, row in data.iterrows():\n",
        "    prompt = row[\"Prompt\"]\n",
        "    response = generate_with_retrieval(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98845f5e",
      "metadata": {
        "id": "98845f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "9dbab194-fe7c-4f4b-8d32-5f78c0839c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "57d266d7ed814f09a7775b4f4d177af9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -c pytorch faiss-cpu=1.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8dQSdQ_uGnB",
        "outputId": "64fbb573-45dc-42ac-9a82-159dc224a19d"
      },
      "id": "o8dQSdQ_uGnB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}